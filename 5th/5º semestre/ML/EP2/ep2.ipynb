{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EP2 - MAC0460 - Introdução ao aprendizado de máquina\n",
    "### Sabrina Araújo da Silva nUSP 12566182"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importações: utilizei as bibliotecas numpy e pandas, além da biblioteca de modelos Scikit-Learn que irá ser usada posteriormente. \n",
    "\n",
    "Utilizei classes específicas do Scikit-Learn, como o GridSearchCV para busca de parâmetros, o StandardScaler para pré-processamento de dados, e as classes para os modelos de Regressão Logística, SVM, Decision Tree e Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação do dataset\n",
    "\n",
    "Para importar o dataset utilizei o arquivo \"pokemon.csv\", que contém os dados sobre os Pokémons.\n",
    "\n",
    "Para a limpeza dos dados, as colunas que não são relevantes para a análise ou contêm muitos valores ausentes são excluídas do dataset. \"type2\", \"abilities\" e \"classfication\" foram retiradas como definido no enunciado do EP. Já as colunas \"is_legendary\", \"percentage_male\", \"japanese_name\", \"name\", \"weight_kg\", \"height_m\" foram retiradas por causa de conflitos no código, como valores iguais a 0, dados ausentes ou dados igual a NaN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     against_electric  attack  base_egg_steps  base_happiness  base_total  \\\n",
      "6                 2.0      48            5120              70         314   \n",
      "7                 2.0      63            5120              70         405   \n",
      "8                 2.0     103            5120              70         630   \n",
      "15                2.0      45            3840              70         251   \n",
      "16                2.0      60            3840              70         349   \n",
      "..                ...     ...             ...             ...         ...   \n",
      "772               1.0      95           30720               0         570   \n",
      "774               1.0     115            5120              70         480   \n",
      "778               2.0     105            3840              70         475   \n",
      "779               0.5      60            5120              70         485   \n",
      "787               2.0      75            3840              70         570   \n",
      "\n",
      "    capture_rate  defense  experience_growth  hp  pokedex_number  sp_attack  \\\n",
      "6             45       65            1059860  44               7         50   \n",
      "7             45       80            1059860  59               8         65   \n",
      "8             45      120            1059860  79               9        135   \n",
      "15           255       40            1059860  40              16         35   \n",
      "16           120       55            1059860  63              17         50   \n",
      "..           ...      ...                ...  ..             ...        ...   \n",
      "772            3       95            1250000  95             773         95   \n",
      "774           45       65            1250000  65             775         75   \n",
      "778           80       70            1000000  68             779         70   \n",
      "779           70       85            1000000  78             780        135   \n",
      "787            3      115            1250000  70             788         95   \n",
      "\n",
      "     sp_defense  speed  generation  \n",
      "6            64     43           1  \n",
      "7            80     58           1  \n",
      "8           115     78           1  \n",
      "15           35     56           1  \n",
      "16           50     71           1  \n",
      "..          ...    ...         ...  \n",
      "772          95     95           7  \n",
      "774          95     65           7  \n",
      "778          70     92           7  \n",
      "779          91     36           7  \n",
      "787         130     85           7  \n",
      "\n",
      "[219 rows x 14 columns]\n",
      "6       water\n",
      "7       water\n",
      "8       water\n",
      "15     normal\n",
      "16     normal\n",
      "        ...  \n",
      "772    normal\n",
      "774    normal\n",
      "778     water\n",
      "779    normal\n",
      "787     water\n",
      "Name: type1, Length: 219, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Importação do dataset\n",
    "arquivoDataset = \"pokemon.csv\"\n",
    "data = pd.read_csv(arquivoDataset)\n",
    "\n",
    "# Colunas não necessárias\n",
    "colunasExcluir = ['type2', 'abilities', 'classfication', 'is_legendary', 'percentage_male', 'japanese_name', 'name', 'weight_kg', 'height_m']\n",
    "\n",
    "# Colunas against_x que sejam diferentes de against_electric\n",
    "colunasAgainstExcluir = [coluna for coluna in data.columns if coluna.startswith('against_') and coluna != 'against_electric']\n",
    "\n",
    "# Retira colunas selecionadas\n",
    "data = data.drop(columns=colunasExcluir + colunasAgainstExcluir)\n",
    "\n",
    "# Filtra o dataset para manter apenas as linhas com type1 igual a \"normal\" ou \"water\"\n",
    "data = data[data['type1'].isin(['normal', 'water'])]\n",
    "\n",
    "X = data.drop(columns=['type1'])\n",
    "y = data['type1'] \n",
    "\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classe StandardScaler foi importada para realizar a padronização dos dados, garantindo que todas as variáveis tenham a mesma escala e evitando a influência de outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5703509  -0.88292165 -0.16884391 ... -0.13308681 -0.91779641\n",
      "  -1.23603412]\n",
      " [ 0.5703509  -0.37736167 -0.16884391 ...  0.44621279 -0.33474454\n",
      "  -1.23603412]\n",
      " [ 0.5703509   0.97079829 -0.16884391 ...  1.71343065  0.44265795\n",
      "  -1.23603412]\n",
      " ...\n",
      " [ 0.5703509   1.03820628 -0.42562735 ...  0.08415054  0.98683969\n",
      "   1.92378851]\n",
      " [-1.47730234 -0.47847366 -0.16884391 ...  0.84448126 -1.18988728\n",
      "   1.92378851]\n",
      " [ 0.5703509   0.02708632 -0.42562735 ...  2.25652403  0.71474882\n",
      "   1.92378851]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X)\n",
    "X_std = sc.transform(X)\n",
    "\n",
    "print(X_std)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O dataset foi dividido em duas partes: 75% foi alocado para o conjunto \"atual\", que contém os dados a serem utilizados para o treinamento atual, enquanto 25% foi destinado ao conjunto \"final\", que servirá para testar todos os modelos. O conjunto \"atual\" foi posteriormente subdividido em 70% para o conjunto de treinamento (X_train e y_train) e 30% para o conjunto de teste (X_test e y_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Divide o dataset em conjuntos de treinamento e teste\n",
    "X_atual, X_final, y_atual, y_final = train_test_split(X_std, y, test_size=0.25, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_atual, y_atual, test_size=0.3, random_state=42)\n",
    "\n",
    "#print(X_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento\n",
    "\n",
    "Agora, usamos os conjuntos X_train e y_train para treinar os seguintes modelos:\n",
    "\n",
    "- Regressão Logística\n",
    "- Support Vector Machine\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "\n",
    "E posteriormente testamos os modelos com os conjuntos X_test e y_test."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regressão Logística\n",
    "\n",
    "O modelo de regressão logística foi importado da biblioteca Scikit-learn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LRmodel = LogisticRegression()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seleção dos melhores parâmetros é realizada utilizando k-cross validation e grid search. Nesse processo, foi considerado o regularization parameter, que está indiretamente relacionado ao parâmetro C. O parâmetro C é o inverso do parâmetro de regularização, ou seja, quanto menor o valor de C, maior será a regularização aplicada ao modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor parâmetro: {'C': 1}\n",
      "Acurácia do modelo RL: 0.74\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Procura os melhores parâmetros\n",
    "kfold = model_selection.KFold(n_splits=10)\n",
    "parameters = {'C': [0.1, 1, 10, 100]}\n",
    "grid_search = GridSearchCV(LRmodel, parameters, scoring='accuracy', cv=kfold)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Melhor parâmetro:\", grid_search.best_params_)\n",
    "\n",
    "# Treina o modelo com os melhores parâmetros\n",
    "LRbest = grid_search.best_estimator_\n",
    "LRbest.fit(X_train, y_train)\n",
    "\n",
    "# Acurácia do modelo com os melhores parâmetros em relação aos dados de teste\n",
    "accuracy = LRbest.score(X_test, y_test)\n",
    "print(\"Acurácia do modelo RL: {:.2f}\".format(accuracy))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM - Support Vector Machine\n",
    "\n",
    "Para usar o modelo SVM, usamos a classe SVC (Support Vector Classifier) do módulo svm do Scikit-learn. A classe SVC é utilizada para problemas de classificação com SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "SVMmodel = svm.SVC()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seleção dos melhores valores para os parâmetros C, kernel, gamma e grau do polinômio é realizada utilizando k-cross validation e grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros: {'C': 1, 'degree': 2, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Acurácia do modelo SVM: 0.72\n"
     ]
    }
   ],
   "source": [
    "# Procura os melhores parâmetros\n",
    "kfold = model_selection.KFold(n_splits=10)\n",
    "parameters = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf', 'sigmoid'],\n",
    "              'gamma': ['scale', 'auto', 0.1, 1], 'degree': [2, 3, 4]}\n",
    "grid_search = GridSearchCV(SVMmodel, parameters, scoring='accuracy', cv=kfold)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Melhores parâmetros:\", grid_search.best_params_)\n",
    "\n",
    "# Treina o modelo com os melhores parâmetros\n",
    "SVMbest = grid_search.best_estimator_\n",
    "SVMbest.fit(X_train, y_train)\n",
    "\n",
    "# Acurácia do modelo em relação aos dados de teste\n",
    "accuracy = SVMbest.score(X_test, y_test)\n",
    "print(\"Acurácia do modelo SVM: {:.2f}\".format(accuracy))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree\n",
    "\n",
    "O modelo Decision Tree foi importado da biblioteca Scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "DTmodel = DecisionTreeClassifier()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seleção dos melhores valores para os parâmetros \"maximum depth of the tree\" e \"minimum number of samples required to be at a leaf node\" é realizada utilizando k-cross validation e grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo DT: 0.90\n"
     ]
    }
   ],
   "source": [
    "# Procura os melhores parâmetros\n",
    "kfold = model_selection.KFold(n_splits=10)\n",
    "parameters = {'max_depth': [None, 5, 10, 20], 'min_samples_leaf': [1, 2, 5, 10]}\n",
    "grid_search = GridSearchCV(DTmodel, parameters, scoring='accuracy', cv=kfold)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Treina o modelo com os melhores parâmetros\n",
    "DTbest = grid_search.best_estimator_\n",
    "DTbest.fit(X_train, y_train)\n",
    "\n",
    "# Acurácia do modelo em relação aos dados de teste\n",
    "accuracy = DTbest.score(X_test, y_test)\n",
    "print(\"Acurácia do modelo DT: {:.2f}\".format(accuracy))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest\n",
    "\n",
    "O modelo Random Forest foi importado da biblioteca Scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RFmodel = RandomForestClassifier()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seleção dos melhores valores para os parâmetros \"number of estimators\", \"maximum depth of the tree\" e \"minimum number of samples required to be at a leaf node\" é realizada utilizando k-cross validation e grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros: {'max_depth': 5, 'min_samples_leaf': 1, 'n_estimators': 500}\n",
      "Acurácia do modelo RF: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Procura os melhores parâmetros\n",
    "kfold = model_selection.KFold(n_splits=10)\n",
    "parameters = {'n_estimators': [100, 200, 500], 'max_depth': [None, 5, 10], 'min_samples_leaf': [1, 2, 5]}\n",
    "grid_search = GridSearchCV(RFmodel, parameters, scoring='accuracy', cv=kfold)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Melhores parâmetros:\", grid_search.best_params_)\n",
    "\n",
    "# Treina o modelo com os melhores parâmetros\n",
    "RFbest = grid_search.best_estimator_\n",
    "RFbest.fit(X_train, y_train)\n",
    "\n",
    "# Acurácia do modelo em relação aos dados de teste\n",
    "accuracy = RFbest.score(X_test, y_test)\n",
    "print(\"Acurácia do modelo RF: {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outros três modelos de classificação serão testados:\n",
    "\n",
    "- Perceptron\n",
    "- K-Nearest Neighbors (KNN)\n",
    "- Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptron\n",
    "\n",
    "O modelo Perceptron foi importado da biblioteca Scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros: {'alpha': 0.0001, 'max_iter': 100}\n",
      "Acurácia do modelo Perceptron: 0.68\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "Pmodel = Perceptron()\n",
    "\n",
    "# Procura os melhores parâmetros\n",
    "kfold = model_selection.KFold(n_splits=10)\n",
    "parameters = {'alpha': [0.0001, 0.001, 0.01], 'max_iter': [100, 1000, 10000]}\n",
    "grid_search = GridSearchCV(Pmodel, parameters, scoring='accuracy', cv=kfold)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Melhores parâmetros:\", grid_search.best_params_)\n",
    "\n",
    "# Treina o modelo com os melhores parâmetros\n",
    "Pbest = grid_search.best_estimator_\n",
    "Pbest.fit(X_train, y_train)\n",
    "\n",
    "# Acurácia do modelo em relação aos dados de teste\n",
    "accuracy = Pbest.score(X_test, y_test)\n",
    "print(\"Acurácia do modelo Perceptron: {:.2f}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbors (KNN)\n",
    "\n",
    "O KNN se baseia nas instâncias mais próximas para classificar novas instâncias. O modelo K-Nearest Neighbors (KNN) foi importado da biblioteca Scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros: {'n_neighbors': 5, 'weights': 'uniform'}\n",
      "Acurácia do modelo KNN: 0.72\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "KNNmodel = KNeighborsClassifier()\n",
    "\n",
    "# Procura os melhores valores para os parâmetros n_neighbors e weights\n",
    "kfold = model_selection.KFold(n_splits=10)\n",
    "parameters = {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance']}\n",
    "grid_search = GridSearchCV(KNNmodel, parameters, scoring='accuracy', cv=kfold)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Melhores parâmetros:\", grid_search.best_params_)\n",
    "\n",
    "# Treina o modelo com os melhores parâmetros\n",
    "KNNbest = grid_search.best_estimator_\n",
    "KNNbest.fit(X_train, y_train)\n",
    "\n",
    "# Acurácia do modelo em relação aos dados de teste\n",
    "accuracy = KNNbest.score(X_test, y_test)\n",
    "print(\"Acurácia do modelo KNN: {:.2f}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes\n",
    "\n",
    "O Naive Bayes assume independência condicional e estima probabilidades. O modelo Naive Bayes foi importado da classe GaussianNB da biblioteca Scikit-learn. Esse modelo não posssui ajuste de parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo Naive Bayes: 0.66\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "NBmodel = GaussianNB()\n",
    "\n",
    "# Treina o modelo\n",
    "NBmodel.fit(X_train, y_train)\n",
    "\n",
    "# Acurácia do modelo em relação aos dados de teste\n",
    "accuracy = NBmodel.score(X_test, y_test)\n",
    "print(\"Acurácia do modelo Naive Bayes: {:.2f}\".format(accuracy))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha do melhor modelo\n",
    "\n",
    "Agora será utilizado o conjunto de dados que foi separado previamente (X_final e y_final) para testar a acurácia de todos os modelos após o treinamento. Com base na acurácia final, é definido o melhor modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia final da Regressão Logística: 0.80\n",
      "Acurácia final do SVM: 0.80\n",
      "Acurácia final da Decision Tree: 0.85\n",
      "Acurácia final da Random Forest: 0.87\n",
      "\n",
      "Acurácia final do Perceptron: 0.60\n",
      "Acurácia final do K-Nearest Neighbors: 0.75\n",
      "Acurácia final do Naive Bayes: 0.75\n",
      "\n",
      "O melhor modelo é o Random Forest.\n"
     ]
    }
   ],
   "source": [
    "# Imprime os valores de acurácia de todos os modelos\n",
    "print('Acurácia final da Regressão Logística: {:.2f}'.format(LRbest.score(X_final, y_final)))\n",
    "print('Acurácia final do SVM: {:.2f}'.format(SVMbest.score(X_final, y_final)))\n",
    "print('Acurácia final da Decision Tree: {:.2f}'.format(DTbest.score(X_final, y_final)))\n",
    "print('Acurácia final da Random Forest: {:.2f}'.format(RFbest.score(X_final, y_final)))\n",
    "print()\n",
    "print('Acurácia final do Perceptron: {:.2f}'.format(Pbest.score(X_final, y_final)))\n",
    "print('Acurácia final do K-Nearest Neighbors: {:.2f}'.format(KNNbest.score(X_final, y_final)))\n",
    "print('Acurácia final do Naive Bayes: {:.2f}'.format(NBmodel.score(X_final, y_final)))\n",
    "print()\n",
    "\n",
    "# Identifica o melhor modelo com base na maior acurácia\n",
    "melhor_modelo = max([LRbest.score(X_final, y_final), SVMbest.score(X_final, y_final), DTbest.score(X_final, y_final), RFbest.score(X_final, y_final)])\n",
    "if melhor_modelo == LRbest.score(X_final, y_final):\n",
    "    print(\"O melhor modelo é a Regressão Logística.\")\n",
    "elif melhor_modelo == SVMbest.score(X_final, y_final):\n",
    "    print(\"O melhor modelo é o SVM.\")\n",
    "elif melhor_modelo == DTbest.score(X_final, y_final):\n",
    "    print(\"O melhor modelo é a Decision Tree.\")\n",
    "elif melhor_modelo == RFbest.score(X_final, y_final):\n",
    "    print(\"O melhor modelo é o Random Forest.\")\n",
    "elif melhor_modelo == Pbest.score(X_final, y_final):\n",
    "    print(\"O melhor modelo é o Naive Bayes.\")\n",
    "elif melhor_modelo == KNNbest.score(X_final, y_final):\n",
    "    print(\"O melhor modelo é o K-Nearest Neighbors.\")\n",
    "elif melhor_modelo == NBmodel.score(X_final, y_final):\n",
    "    print(\"O melhor modelo é o Naive Bayes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrizes de confusão\n",
    "\n",
    "Com base no conjunto de dados para o teste final, os resultados foram representados abaixo em matrizes de confusão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão para Regressão Logística:\n",
      "[[23  7]\n",
      " [ 4 21]]\n",
      "\n",
      "Matriz de confusão para SVM:\n",
      "[[23  7]\n",
      " [ 4 21]]\n",
      "\n",
      "Matriz de confusão para Decision Tree:\n",
      "[[20 10]\n",
      " [ 3 22]]\n",
      "\n",
      "Matriz de confusão para Random Forest:\n",
      "[[24  6]\n",
      " [ 1 24]]\n",
      "\n",
      "Matriz de confusão para Perceptron:\n",
      "[[15 15]\n",
      " [ 7 18]]\n",
      "\n",
      "Matriz de confusão para K-Nearest Neighbors:\n",
      "[[20 10]\n",
      " [ 4 21]]\n",
      "\n",
      "Matriz de confusão para Naive Bayes:\n",
      "[[22  8]\n",
      " [ 6 19]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Função para calcular e imprimir a matriz de confusão\n",
    "def confusionMatrix(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    confusion = confusion_matrix(y, y_pred)\n",
    "    print(confusion)\n",
    "\n",
    "# Matriz de confusão para Regressão Logística\n",
    "print(\"Matriz de confusão para Regressão Logística:\")\n",
    "confusionMatrix(LRbest, X_final, y_final)\n",
    "print()\n",
    "\n",
    "# Matriz de confusão para SVM\n",
    "print(\"Matriz de confusão para SVM:\")\n",
    "confusionMatrix(SVMbest, X_final, y_final)\n",
    "print()\n",
    "\n",
    "# Matriz de confusão para Decision Tree\n",
    "print(\"Matriz de confusão para Decision Tree:\")\n",
    "confusionMatrix(DTbest, X_final, y_final)\n",
    "print()\n",
    "\n",
    "# Matriz de confusão para Random Forest\n",
    "print(\"Matriz de confusão para Random Forest:\")\n",
    "confusionMatrix(RFbest, X_final, y_final)\n",
    "print()\n",
    "\n",
    "# Matriz de confusão para Perceptron\n",
    "print(\"Matriz de confusão para Perceptron:\")\n",
    "confusionMatrix(Pbest, X_final, y_final)\n",
    "print()\n",
    "\n",
    "# Matriz de confusão para KNN\n",
    "print(\"Matriz de confusão para K-Nearest Neighbors:\")\n",
    "confusionMatrix(KNNbest, X_final, y_final)\n",
    "print()\n",
    "\n",
    "# Matriz de confusão para Naive Bayes\n",
    "print(\"Matriz de confusão para Naive Bayes:\")\n",
    "confusionMatrix(NBmodel, X_final, y_final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importância das features\n",
    "\n",
    "Uso da Random Forest para obter uma estimativa de quais features foram mais importantes para a classificação dos pokémons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importância das Features:\n",
      "              Feature  Importance\n",
      "0    against_electric    0.243598\n",
      "10          sp_attack    0.109782\n",
      "4          base_total    0.076333\n",
      "2      base_egg_steps    0.074573\n",
      "1              attack    0.073187\n",
      "12              speed    0.065950\n",
      "11         sp_defense    0.064077\n",
      "9      pokedex_number    0.063630\n",
      "6             defense    0.063455\n",
      "8                  hp    0.054710\n",
      "7   experience_growth    0.038081\n",
      "5        capture_rate    0.034194\n",
      "13         generation    0.030888\n",
      "3      base_happiness    0.007543\n"
     ]
    }
   ],
   "source": [
    "# Obtém as importâncias das features usando o modelo Random Forest\n",
    "importances = RFbest.feature_importances_\n",
    "feature_importances = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
    "feature_importances = feature_importances.sort_values('Importance', ascending=False)\n",
    "\n",
    "# Imprime as importâncias das features\n",
    "print(\"Importância das Features:\")\n",
    "print(feature_importances)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
